# Auto-Summarization Pipeline Environment Configuration
# Story 4-4: Auto-Summarization Pipeline
# Copy this file to .env and update values for your environment

# =============================================================================
# SUMMARIZATION PIPELINE SETTINGS
# =============================================================================

# Enable/disable auto-summarization
SUMMARIZATION_ENABLED=true

# Messages between summaries (default: 10)
SUMMARIZATION_TRIGGER_INTERVAL=10

# Minimum time between summaries for same conversation (seconds)
SUMMARIZATION_COOLDOWN_SECONDS=60

# Maximum concurrent summarization jobs
MAX_CONCURRENT_SUMMARIZATION_JOBS=2

# =============================================================================
# LLM CONFIGURATION (DEEPSEEK VIA LITELLM)
# =============================================================================

# LiteLLM proxy endpoint
LITELLM_PROXY_URL=http://litellm-proxy:4000

# DeepSeek model to use
DEEPSEEK_MODEL=deepseek-main

# Request timeout in seconds
SUMMARIZATION_TIMEOUT_SECONDS=30

# Maximum retry attempts for failed LLM calls
SUMMARIZATION_MAX_RETRIES=3

# Delay between retries (milliseconds)
SUMMARIZATION_RETRY_DELAY_MS=1000

# =============================================================================
# SUMMARY QUALITY SETTINGS
# =============================================================================

# Minimum summary length (characters)
SUMMARIZATION_MIN_LENGTH=20

# Maximum summary length (characters)
SUMMARIZATION_MAX_LENGTH=300

# Temperature for LLM generation (0.0-2.0)
SUMMARIZATION_TEMPERATURE=0.3

# Maximum tokens for LLM response
SUMMARIZATION_MAX_TOKENS=150

# Confidence score for auto-generated summaries
AUTO_SUMMARY_CONFIDENCE=0.9

# =============================================================================
# DUPLICATE DETECTION
# =============================================================================

# Similarity threshold for duplicate detection (0.0-1.0)
SUMMARIZATION_DUPLICATE_THRESHOLD=0.8

# Time window to check for duplicates (hours)
SUMMARIZATION_DUPLICATE_WINDOW_HOURS=1

# =============================================================================
# PERFORMANCE TARGETS
# =============================================================================

# Target processing time (milliseconds)
TARGET_PROCESSING_TIME_MS=2000

# Maximum acceptable processing time (milliseconds)
MAX_PROCESSING_TIME_MS=10000

# Target success rate percentage
TARGET_SUCCESS_RATE=95.0

# Queue processing timeout (seconds)
QUEUE_PROCESSING_TIMEOUT_SECONDS=30

# Individual job timeout (seconds)
SUMMARIZATION_JOB_TIMEOUT_SECONDS=120

# =============================================================================
# WORKER CONFIGURATION
# =============================================================================

# Health check interval (seconds)
WORKER_HEALTH_CHECK_INTERVAL=60

# Metrics reporting interval (seconds)
WORKER_METRICS_INTERVAL=300

# Worker log level
WORKER_LOG_LEVEL=INFO

# Maximum concurrent jobs per worker
WORKER_MAX_CONCURRENT_JOBS=2

# =============================================================================
# MONITORING AND ALERTING
# =============================================================================

# Metrics retention period (days)
METRICS_RETENTION_DAYS=90

# Trigger logs retention period (days)
TRIGGER_LOGS_RETENTION_DAYS=30

# Performance alert threshold (milliseconds)
PERFORMANCE_ALERT_THRESHOLD_MS=5000

# Failure rate alert threshold (percentage)
FAILURE_RATE_ALERT_THRESHOLD=10.0

# =============================================================================
# INTEGRATION SETTINGS
# =============================================================================

# Auto-inject summaries into conversation context
SUMMARIZATION_AUTO_INJECT=true

# Maximum summary topics to extract
MAX_SUMMARY_TOPICS=5

# Enable sentiment analysis
SENTIMENT_ANALYSIS_ENABLED=true

# Memory category for summaries
SUMMARY_MEMORY_CATEGORY=summary

# Memory source type for summaries
SUMMARY_MEMORY_SOURCE_TYPE=auto_summary

# =============================================================================
# REDIS CONFIGURATION (BACKGROUND JOBS)
# =============================================================================

REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_SOCKET_TIMEOUT=5
REDIS_SOCKET_CONNECT_TIMEOUT=5

# =============================================================================
# POSTGRESQL CONFIGURATION
# =============================================================================

POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=manus
POSTGRES_USER=manus
POSTGRES_PASSWORD=
POSTGRES_POOL_SIZE=10
POSTGRES_MAX_OVERFLOW=20

# =============================================================================
# DEVELOPMENT/PRODUCTION SETTINGS
# =============================================================================

# Environment: development, staging, production
ENVIRONMENT=development

# Enable debug logging
DEBUG=false

# Log summarization events to file
LOG_SUMMARIZATION_EVENTS=true
LOG_SUMMARIZATION_PATH=/var/log/summarization.log

# =============================================================================
# RATE LIMITING AND THROTTLING
# =============================================================================

# Rate limit requests to LLM per minute
LLM_RATE_LIMIT_PER_MINUTE=60

# Throttle processing when queue is full
THROTTLE_WHEN_QUEUE_FULL=true

# Maximum queue length before throttling
MAX_QUEUE_LENGTH_BEFORE_THROTTLE=100

# =============================================================================
# EXPERIMENTAL FEATURES
# =============================================================================

# Enable experimental topic clustering
EXPERIMENTAL_TOPIC_CLUSTERING=false

# Enable conversation context enhancement
EXPERIMENTAL_CONTEXT_ENHANCE=false

# Enable advanced sentiment analysis
EXPERIMENTAL_ADVANCED_SENTIMENT=false